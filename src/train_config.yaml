
hyperparameters: 
  batch_size: 32
  learning_rate: 0.001
  epochs: &epochs_value 4
  num_workers: 6
  project_name: "the-best-DeiT-FER"
  user: "thebestofthebest"
  seed: 1234
  data_path: 'data/processed/'

# Sweep configurations
program: src/train_model.py
method: random
parameters:
  learning_rate:
    values: [0.001, 0.01, 0.1]
  epochs:
    values: [5, 10, 15]
  optimizers:
    values: ['adam', 'sgd']
  batch_size:
    distribution: 'q_log_uniform_values'
    q: 8
    min: 32
    max: 256


